using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using Syn.Speech.Logging;
using Syn.Speech.Helper;
using Syn.Speech.Linguist.Dictionary;
using Syn.Speech.Linguist.Util;
using Syn.Speech.Util;
using Syn.Speech.Util.Props;

//PATROLLED + REFACTORED
namespace Syn.Speech.Linguist.Language.NGram.Large
{
    /// <summary>
    /// Language model that uses a binary NGram language model file ("DMP file")
    /// generated by the SphinxBase sphinx_lm_convert.
    /// </summary>
    public class LargeNGramModel : LanguageModel
    {
         /**
         * The property for the name of the file that logs all the queried N-grams.
         * If this property is set to null, it means that the queried N-grams are
         * not logged.
         */
        [S4String(Mandatory = false)]
        public static string PropQueryLogFile = "queryLogFile";

        /** The property that defines that maximum number of ngrams to be cached */
        [S4Integer(DefaultValue = 100000)]
        public static string PropNgramCacheSize = "ngramCacheSize";

        /**
         * The property that controls whether the ngram caches are cleared after
         * every utterance
         */
        [S4Boolean(DefaultValue = false)]
        public static string PropClearCachesAfterUtterance = "clearCachesAfterUtterance";

        /** The property that defines the language weight for the search */
        [S4Double(DefaultValue = 1.0f)]
        public static string PropLanguageWeight = "languageWeight";

        /**
         * The property that controls whether or not the language model will apply
         * the language weight and word insertion probability
         */
        [S4Boolean(DefaultValue = false)]
        public static string PropApplyLanguageWeightAndWip = "applyLanguageWeightAndWip";

        /** Word insertion probability property */
        [S4Double(DefaultValue = 1.0f)]
        public static string PropWordInsertionProbability =  "wordInsertionProbability";

        /** If true, use full bigram information to determine smear */
        [S4Boolean(DefaultValue = false)]
        public static string PropFullSmear = "fullSmear";

        /**
         * The number of bytes per N-gram in the LM file generated by the
         * CMU-Cambridge Statistical Language Modeling Toolkit.
         */
        public static int BytesPerNgram = 4;
        public static int BytesPerNmaxgram = 2;

        private const uint SmearMagic = 0xC0CAC01A; // things go better

        // ------------------------------
        // Configuration data
        // ------------------------------
        public URL Location;
        protected LogMath LogMath;

        protected int NgramCacheSize;
        protected Boolean ClearCacheAfterUtterance;

        protected Boolean FullSmear;

        protected IDictionary Dictionary;
        protected string Format;
        protected Boolean ApplyLanguageWeightAndWip;
        protected float LanguageWeight;
        protected float UnigramWeight;
        protected double Wip;

        // -------------------------------
        // Statistics
        // -------------------------------
        private int _smearTermCount;
        protected string NgramLogFile;

        // -------------------------------
        // subcomponents
        // --------------------------------
        private BinaryLoader _loader;
        private StreamWriter _logFile;

        // -------------------------------
        // Working data
        // --------------------------------
        private HashMap<Word, UnigramProbability> _unigramIDMap;
        private HashMap<WordSequence, NGramBuffer>[] _loadedNGramBuffers;
        private LRUCache<WordSequence, Float> _ngramDepthCache;
        private Dictionary<long, Float> _bigramSmearMap;

        private NGramBuffer[] _loadedBigramBuffers;
        private UnigramProbability[] _unigrams;
        private int[][] _ngramSegmentTable;
        private float[][] _ngramProbTable;
        private float[][] _ngramBackoffTable;
        private float[] _unigramSmearTerm;

        public LargeNGramModel(String format, URL location, string ngramLogFile,
                int maxNGramCacheSize, Boolean clearCacheAfterUtterance,
                int maxDepth, IDictionary dictionary,
                Boolean applyLanguageWeightAndWip, float languageWeight,
                double wip, float unigramWeight, Boolean fullSmear)
        {

            Format = format;
            Location = location;
            NgramLogFile = ngramLogFile;
            NgramCacheSize = maxNGramCacheSize;
            ClearCacheAfterUtterance = clearCacheAfterUtterance;
            MaxDepth = maxDepth;
            LogMath = LogMath.GetLogMath();
            Dictionary = dictionary;
            ApplyLanguageWeightAndWip = applyLanguageWeightAndWip;
            LanguageWeight = languageWeight;
            Wip = wip;
            UnigramWeight = unigramWeight;
            FullSmear = fullSmear;
        }

        public LargeNGramModel() {

        }

        /*
         * (non-Javadoc)
         * @see
         * edu.cmu.sphinx.util.props.Configurable#newProperties(edu.cmu.sphinx.
         * util.props.PropertySheet)
         */
        public override void NewProperties(PropertySheet ps)
        {
            Location = ConfigurationManagerUtils.GetResource(PropLocation, ps);
            NgramLogFile = ps.GetString(PropQueryLogFile);
            NgramCacheSize = ps.GetInt(PropNgramCacheSize);
            ClearCacheAfterUtterance = ps.GetBoolean(PropClearCachesAfterUtterance);
            MaxDepth = ps.GetInt(PropMaxDepth);
            Dictionary = (IDictionary) ps.GetComponent(PropDictionary);
            ApplyLanguageWeightAndWip = ps.GetBoolean(PropApplyLanguageWeightAndWip);
            LanguageWeight = ps.GetFloat(PropLanguageWeight);
            Wip = ps.GetDouble(PropWordInsertionProbability);
            UnigramWeight = ps.GetFloat(PropUnigramWeight);
            FullSmear = ps.GetBoolean(PropFullSmear);
        }

        /*
         * (non-Javadoc)
         * @see edu.cmu.sphinx.linguist.language.ngram.LanguageModel#allocate()
         */
        public override void Allocate() 
        {
            TimerPool.GetTimer(this, "Load LM").Start();

            this.LogInfo("Loading n-gram language model from: " + Location);

            // create the log file if specified
            if (NgramLogFile != null)
                _logFile = new StreamWriter(NgramLogFile);
            //Java's URL.getProtocol()==null
            if (!String.IsNullOrEmpty(Location.Path)) 
            {
                try {
                    _loader =
                        new BinaryLoader(new FileInfo(Location.Path), Format,
                                         ApplyLanguageWeightAndWip, LanguageWeight,Wip,
                                         UnigramWeight);
                } 
                catch (Exception e) 
                {
                    _loader =
                        new BinaryLoader(new FileInfo(Location.Path), Format,
                                         ApplyLanguageWeightAndWip, LanguageWeight, Wip,
                                         UnigramWeight);
                }
            } else {
                _loader =
                    new BinaryStreamLoader(Location.Path, Format,
                                           ApplyLanguageWeightAndWip,LanguageWeight, Wip,
                                           UnigramWeight);
            }

            _unigramIDMap = new HashMap<Word, UnigramProbability>();
            _unigrams = _loader.Unigrams;
            _loadedNGramBuffers = new HashMap<WordSequence, NGramBuffer>[_loader.MaxDepth];
            _ngramProbTable = new float[_loader.MaxDepth][];
            _ngramBackoffTable = new float[_loader.MaxDepth][];
            _ngramSegmentTable = new int[_loader.MaxDepth][];

            for (var i = 1; i <= _loader.MaxDepth; i++) 
            {
                _loadedNGramBuffers[i - 1] = new HashMap<WordSequence, NGramBuffer>();

                if (i >= 2)
                    _ngramProbTable[i - 1] = _loader.GetNGramProbabilities(i);

                if (i > 2) {
                    _ngramBackoffTable[i - 1] = _loader.GetNGramBackoffWeights(i);
                    _ngramSegmentTable[i - 1] = _loader.GetNGramSegments(i);
                }
            }

            _ngramDepthCache = new LRUCache<WordSequence, Float>(NgramCacheSize);
            if (Dictionary != null)
                BuildUnigramIDMap(Dictionary);
            else
                BuildUnigramIDMap();
            _loadedBigramBuffers = new NGramBuffer[_unigrams.Length];

            if (MaxDepth <= 0 || MaxDepth > _loader.MaxDepth)
                MaxDepth = _loader.MaxDepth;

            for (var i = 1; i <= _loader.MaxDepth; i++)
                this.LogInfo(i + "-grams: " +
                            _loader.GetNumberNGrams(i));

            if (FullSmear) {
                this.LogInfo("Full Smear");
                try {
                    this.LogInfo("... Reading ...");
                    ReadSmearInfo("smear.dat");
                    this.LogInfo("... Done ");
                } catch (IOException e) {
                    this.LogInfo("... " + e);
                    this.LogInfo("... Calculating");
                    BuildSmearInfo();
                    this.LogInfo("... Writing");
                    // writeSmearInfo("smear.dat");
                    this.LogInfo("... Done");
                }
            }

            TimerPool.GetTimer(this, "Load LM").Stop();
        }

        /*
         * (non-Javadoc)
         * @see edu.cmu.sphinx.linguist.language.ngram.LanguageModel#deallocate()
         */
        public override void Deallocate()
        {
            _loader.Deallocate();
        }

        /**
         * Builds the map from unigram to unigramID. Also finds the startWordID and
         * endWordID.
         *
         * @param dictionary
         * */
        private void BuildUnigramIDMap(IDictionary dictionary) 
        {
            var missingWords = 0;
            var words = _loader.Words;
            for (var i = 0; i < words.Length; i++) 
            {
                var word = dictionary.GetWord(words[i]);

                if (word == null) {
                    Trace.TraceWarning("The dictionary is missing a phonetic transcription for the word '" +
                                   words[i] + "'");
                    missingWords++;
                }

                _unigramIDMap.Put(word, _unigrams[i]);
                //unigramIDMap.Put(word, );


                //this.LogInfo("Word: " + word);
            }

            if (missingWords > 0)
                Trace.TraceWarning("Dictionary is missing " + missingWords +
                               " words that are contained in the language model.");
        }

        private void BuildUnigramIDMap() 
        {
            var words = _loader.Words;
            for (var i = 0; i < words.Length; i++) 
            {
                var word = new Word(words[i], null, false);

                _unigramIDMap.Put(word, _unigrams[i]);
            }
        }

        /** Called after a recognition */
        public void Stop() 
        {
            ClearCache();

            if (_logFile != null) 
            {
                _logFile.WriteLine("<END_UTT>");
                _logFile.Flush();
            }
        }

        /** Clears the various N-gram caches. */
        private void ClearCache() {
            for (var i = 0; i < _loadedBigramBuffers.Length; i++) 
            {
                var buffer = _loadedBigramBuffers[i];

                if (buffer != null) {
                    if (!buffer.Used)
                        _loadedBigramBuffers[i] = null; // free the BigramBuffer
                    else
                        buffer.Used = false;
                }
            }

            _loadedBigramBuffers = new NGramBuffer[_unigrams.Length];
            for (var i = 2; i <= _loader.MaxDepth; i++) {
                _loadedNGramBuffers[i - 1] = new HashMap<WordSequence, NGramBuffer>();
            }
            this.LogInfo("LM Cache Size: " + _ngramDepthCache.Count + " Hits: " +
                        NGramHits + " Misses: " + NGramMisses);
            if (ClearCacheAfterUtterance) {
                _ngramDepthCache =
                    new LRUCache<WordSequence, Float>(NgramCacheSize);
            }
        }

        /**
         * Returns predicted probability and depth. Uses caching for high order
         * ngrams.
         *
         * @param wordSequence sequence to get the probability
         */
        public override float GetProbability(WordSequence wordSequence) 
        {
            var numberWords = wordSequence.Size;
            Float probability;

            if (numberWords > MaxDepth) 
            {
                throw new Exception("Unsupported NGram: " + wordSequence.Size);
            }

            if (numberWords == MaxDepth) {
                probability = _ngramDepthCache.Get(wordSequence);

                if (probability != null) {
                    NGramHits++;
                    return probability;
                }
                NGramMisses++;
            }

            probability = GetNGramProbDepth(wordSequence);

            if (numberWords == MaxDepth)
                _ngramDepthCache.Put(wordSequence, probability);

            if (_logFile != null && probability != null)
                _logFile.WriteLine(wordSequence.ToString().Replace("][", " ") +
                                " : " + probability);

            return probability;
        }

        private float GetNGramProbDepth(WordSequence wordSequence) 
        {
            var numberWords = wordSequence.Size;
            var firstWord = wordSequence.GetWord(0);

            if (_loader.GetNumberNGrams(numberWords) == 0 || !HasUnigram(firstWord))
                return GetNGramProbDepth(wordSequence.GetNewest());

            if (numberWords < 2) {
                return GetUnigramProbability(wordSequence);
            }

            var nGProbability = FindNGram(wordSequence);

            if (nGProbability != null) {
                   return _ngramProbTable[numberWords - 1][nGProbability.ProbabilityID];
                //return new ProbDepth(probability, numberWords);
            }

            if (numberWords == 2) {
                var unigramProb = GetUnigram(firstWord);
                var unigramProb1 =
                    GetUnigram(wordSequence.GetWord(1));
                return  unigramProb.LogBackoff 
                    + unigramProb1.LogProbability;
            }

            var nMinus1Gram = FindNGram(wordSequence.GetOldest());

            if (nMinus1Gram != null)
            {
                return _ngramBackoffTable[numberWords - 1][nMinus1Gram.BackoffID] + GetProbability(wordSequence.GetNewest());
            }

            return GetProbability(wordSequence.GetNewest());
        }

        /**
         * Finds or loads the NGram probability of the given NGram.
         *
         * @param wordSequence the NGram to load
         * @return a NGramProbability of the given NGram
         */
        private NGramProbability FindNGram(WordSequence wordSequence) 
        {
            var numberWords = wordSequence.Size;
            NGramProbability nGram = null;

            var oldest = wordSequence.GetOldest();
            var nGramBuffer = _loadedNGramBuffers[numberWords - 1].Get(oldest);
            if (nGramBuffer == null) {
                nGramBuffer = GetNGramBuffer(oldest);
                if (nGramBuffer != null)
                    _loadedNGramBuffers[numberWords - 1].Add(oldest, nGramBuffer);
            }

            if (nGramBuffer != null) {
                var nthWordID = GetWordID(wordSequence.GetWord(numberWords - 1));
                nGram = nGramBuffer.FindNGram(nthWordID);
            }

            return nGram;
        }

        /**
         * Tells if the model is 16 or 32 bits.
         *
         * @return true if 32 bits, false otherwise
         */
        private bool Is32Bits() 
        {
            if (_loader.BytesPerField == 4)
                return true;
            return false;
        }

        /**
         * Loads into a buffer all the NGram followers of the given N-1Gram.
         *
         * @param ws the N-1Gram to find followers
         *
         * @return a NGramBuffer of all the NGram followers of the given sequence
         */
        private NGramBuffer LoadNGramBuffer(WordSequence ws) {
            var firstWordID = GetWordID(ws.GetWord(0));
            int firstCurrentNGramEntry;
            var numberNGrams = 0;
            int size;
            long position;
            var orderBuffer = ws.Size + 1;
            NGramBuffer currentBuffer = null;
            NGramBuffer nMinus1Buffer = null;

            firstCurrentNGramEntry = _unigrams[firstWordID].FirstBigramEntry;
            numberNGrams = GetNumberBigramFollowers(firstWordID) + 1;

            if (numberNGrams == 1) // 1 means that there is no bigram starting with
                                   // firstWordID
                return null;

            if (orderBuffer == 2) {
                size =
                    numberNGrams *
                            ((_loader.MaxDepth == orderBuffer) ? BytesPerNmaxgram
                                    : BytesPerNgram) * _loader.BytesPerField;
                position = _loader.GetNGramOffset(orderBuffer)
                   + firstCurrentNGramEntry
                   * (long)((_loader.MaxDepth == orderBuffer) ? BytesPerNmaxgram
                           : BytesPerNgram) * _loader.BytesPerField;
            } else { // only for ws.size() >= 2
                var lastWordId = GetWordID(ws.GetWord(ws.Size - 1));
                nMinus1Buffer = GetNGramBuffer(ws.GetOldest());
                var index = nMinus1Buffer.FindNGramIndex(lastWordId);

                if (index == -1)
                    return null;

                var firstNMinus1GramEntry = nMinus1Buffer.FirstNGramEntry;
                firstCurrentNGramEntry =
                    GetFirstNGramEntry(nMinus1Buffer.GetNGramProbability(index),
                                       firstNMinus1GramEntry,
                                       orderBuffer);
                var firstNextNGramEntry =
                    GetFirstNGramEntry(nMinus1Buffer.GetNGramProbability(index + 1),
                                       firstNMinus1GramEntry,
                                       orderBuffer);
                numberNGrams = firstNextNGramEntry - firstCurrentNGramEntry;

                if (numberNGrams == 0)
                    return null;

                if (_loader.MaxDepth != orderBuffer)
                    numberNGrams++;

                size = numberNGrams *
                            ((_loader.MaxDepth == orderBuffer) ? BytesPerNmaxgram
                                    : BytesPerNgram) * _loader.BytesPerField;
                position =
                    _loader.GetNGramOffset(orderBuffer) +
                            firstCurrentNGramEntry *
                            (long) ((_loader.MaxDepth == orderBuffer) ? BytesPerNmaxgram
                                    : BytesPerNgram) * _loader.BytesPerField;
            }

            try {
                var buffer = _loader.LoadBuffer(position, size);

                if (_loader.MaxDepth == orderBuffer) {
                    currentBuffer = new NMaxGramBuffer(buffer, numberNGrams,
                                           _loader.GetBigEndian(), Is32Bits(), orderBuffer,
                                           firstCurrentNGramEntry);
                } else {
                    currentBuffer = new NGramBuffer(buffer, numberNGrams,
                                        _loader.GetBigEndian(), Is32Bits(), orderBuffer,
                                        firstCurrentNGramEntry);
                }
            } 
            catch (IOException ioe) 
            {
                Trace.TraceError(ioe.ToString());
                throw new Exception("Error loading " + orderBuffer + "-Grams.");
            }

            return currentBuffer;
        }

        /**
         * Returns the NGrams of the given word sequence
         *
         * @param wordSequence the word sequence from which to get the buffer
         * @return the NGramBuffer of the word sequence
         */
        private NGramBuffer GetNGramBuffer(WordSequence wordSequence) 
        {
            NGramBuffer nGramBuffer = null;
            var order = wordSequence.Size;

            if (order > 1)
                nGramBuffer = _loadedNGramBuffers[order - 1].Get(wordSequence); // better
                                                                               // when
                                                                               // using
                                                                               // containsKey

            if (nGramBuffer == null) {
                nGramBuffer = LoadNGramBuffer(wordSequence);

                if (nGramBuffer != null)
                    Java.Put(_loadedNGramBuffers[order - 1],wordSequence,nGramBuffer); // optimizable
                                                                                  // by
                                                                                  // adding
                                                                                  // an
                                                                                  // 'empty'
                                                                                  // nGramBuffer
            }

            return nGramBuffer;
        }

        /**
         * Returns the index of the first NGram entry of the given N-1Gram
         *
         * @param nMinus1Gram the N-1Gram which first NGram entry we're looking for
         * @param firstNMinus1GramEntry the index of the first N-1Gram entry of the
         *        N-1Gram in question
         * @param n the order of the NGram
         * @return the index of the first NGram entry of the given N-1Gram
         */
        private int GetFirstNGramEntry(NGramProbability nMinus1Gram,int firstNMinus1GramEntry, int n) {
            var firstNGramEntry =
                _ngramSegmentTable[n - 1][(firstNMinus1GramEntry + nMinus1Gram.WhichFollower) >> _loader.GetLogNGramSegmentSize()]
                        + nMinus1Gram.FirstNPlus1GramEntry;

            return firstNGramEntry;
        }

        /**
         * Returns the unigram probability of the given unigram.
         *
         * @param wordSequence the unigram word sequence
         * @return the unigram probability
         */
        private float GetUnigramProbability(WordSequence wordSequence) 
        {
            var unigram = wordSequence.GetWord(0);
            var unigramProb = GetUnigram(unigram);

            if (unigramProb == null)
                throw new Exception("Unigram not in LM: " + unigram);

            return unigramProb.LogProbability;
        }

        /**
         * Returns its UnigramProbability if this language model has the given
         * unigram.
         *
         * @param unigram the unigram to find
         * @return the UnigramProbability, or null if this language model does not
         *         have the unigram
         */
        private UnigramProbability GetUnigram(Word unigram) 
        {
            return _unigramIDMap.Get(unigram);
        }

        /**
         * Returns true if this language model has the given unigram.
         *
         * @param unigram the unigram to find
         * @return true if this LM has this unigram, false otherwise
         */
        private Boolean HasUnigram(Word unigram) 
        {
            return (_unigramIDMap.Get(unigram) != null);
        }

        /**
         * Returns the ID of the given word.
         *
         * @param word the word to find the ID
         * @return the ID of the word
         */
        public int GetWordID(Word word) 
        {
            var probability = GetUnigram(word);

            if (probability == null)
                throw new ArgumentException("No word ID: " + word);
            else
                return probability.WordID;
        }

        /**
         * Returns true if the language model contains the given word
         *
         * @param w
         * @return
         */
        public Boolean HasWord(Word w) 
        {
            return (_unigramIDMap.Get(new Word(w.ToString(), null, false)) != null);
        }

        /**
         * Gets the smear term for the given wordSequence
         *
         * @param wordSequence the word sequence
         * @return the smear term associated with this word sequence
         */
        public float GetSmearOld(WordSequence wordSequence) 
        {
            var smearTerm = 0.0f;

            if (FullSmear) {
                var length = wordSequence.Size;

                if (length > 0) {
                    var wordID = GetWordID(wordSequence.GetWord(length - 1));
                    smearTerm = _unigramSmearTerm[wordID];
                }
            }

            //if (fullSmear)//TODO: UNCOMMET ON RELEASE
                //this.LogInfo("SmearTerm: " + smearTerm);

            return smearTerm;
        }

        int smearCount;
        int smearBigramHit;

        public override float GetSmear(WordSequence wordSequence) 
        {
            var smearTerm = 0.0f;

            if (FullSmear) {
                smearCount++;
                var length = wordSequence.Size;

                if (length == 1) {
                    var wordID = GetWordID(wordSequence.GetWord(0));
                    smearTerm = _unigramSmearTerm[wordID];
                } else if (length >= 2) {
                    var size = wordSequence.Size;
                    var wordID1 = GetWordID(wordSequence.GetWord(size - 2));
                    var wordID2 = GetWordID(wordSequence.GetWord(size - 1));
                    var st = GetSmearTerm(wordID1, wordID2);

                    if (st == null)
                        smearTerm = _unigramSmearTerm[wordID2];
                    else {
                        smearTerm = st;
                        smearBigramHit++;
                    }
                }

                if (smearCount % 100000 == 0)
                    this.LogInfo("Smear hit: " + smearBigramHit + " tot: " +
                                       smearCount);
            }

            return smearTerm;
        }

        /**
         * Returns the number of bigram followers of a word.
         *
         * @param wordID the ID of the word
         * @return the number of bigram followers
         */
        private int GetNumberBigramFollowers(int wordID) 
        {
            if (wordID == _unigrams.Length - 1)
                return 0;
            else
                return _unigrams[wordID + 1].FirstBigramEntry -
                       _unigrams[wordID].FirstBigramEntry;
        }

        /**
         * Returns the maximum depth of the language model
         *
         * @return the maximum depth of the language model
         */

        public override int MaxDepth { get; set; }

        /**
         * Returns the set of words in the language model. The set is unmodifiable.
         *
         * @return the unmodifiable set of words
         */

        public override HashSet<string> Vocabulary
        {
            get
            {
                var words = _loader.Words;
                var vocabulary = new HashSet<string>(words);

                //var toReturn = new IReadOnlyList<string>(loader.getWords());
                return vocabulary; //TODO: should be a ReadOnlyCollection ( but has been set as such for performance )
            }
        }

        /**
         * Returns the number of times when a NGram is queried, but there is no
         * such NGram in the LM (in which case it uses the backoff probabilities).
         *
         * @return the number of NGram misses
         */

        public int NGramMisses { get; private set; }

        /**
         * Returns the number of NGram hits.
         *
         * @return the number of NGram hits
         */

        public int NGramHits { get; private set; }

        /**
         * Returns the bigrams of the given word
         *
         * @param firstWordID the ID of the word
         *
         * @return the bigrams of the word
         */
        private NGramBuffer GetBigramBuffer(int firstWordID) 
        {
            var wd = new Word[1];
            wd[0] = Dictionary.GetWord(_loader.Words[firstWordID]);
            var ws = new WordSequence(wd);

            return LoadNGramBuffer(ws);
        }

        /**
         * Loads into a buffer all the trigram followers of the given bigram.
         *
         * @param firstWordID the ID of the first word
         * @param secondWordID the ID of the second word
         *
         * @return a TrigramBuffer of all the trigram followers of the given two
         *         words
         */
        private NGramBuffer LoadTrigramBuffer(int firstWordID, int secondWordID) 
        {
            var wd = new Word[2];
            wd[0] = Dictionary.GetWord(_loader.Words[firstWordID]);
            wd[1] = Dictionary.GetWord(_loader.Words[secondWordID]);
            var ws = new WordSequence(wd);

            return LoadNGramBuffer(ws);
        }

        private void BuildSmearInfo()
        {
            double s0 = 0;
            double r0 = 0;

            _bigramSmearMap = new Dictionary<long, Float>();

            var ugNumerator = new double[_unigrams.Length];
            var ugDenominator = new double[_unigrams.Length];
            var ugAvgLogProb = new double[_unigrams.Length];

            _unigramSmearTerm = new float[_unigrams.Length];

            foreach (var unigram in _unigrams) 
            {
                var logp = unigram.LogProbability;
                var p = LogMath.LogToLinear(logp);
                s0 += p * logp;
                r0 += p * logp * logp;
            }

            this.LogInfo("R0 S0 " + r0 + ' ' + s0);

            for (var i = 0; i < _loadedBigramBuffers.Length; i++) 
            {
                var bigram = GetBigramBuffer(i);

                if (bigram == null) {
                    _unigramSmearTerm[i] = LogMath.LogOne;
                    continue;
                }

                ugNumerator[i] = 0.0;
                ugDenominator[i] = 0.0;
                ugAvgLogProb[i] = 0.0;

                var logugbackoff = _unigrams[i].LogBackoff;
                var ugbackoff = LogMath.LogToLinear(logugbackoff);

                for (var j = 0; j < bigram.NumberNGrams; j++) {
                    var wordID = bigram.GetWordID(j);
                    var bgProb = bigram.GetNGramProbability(j);

                    var logugprob = _unigrams[wordID].LogProbability;
                    var logbgprob = _ngramProbTable[1][bgProb.ProbabilityID];

                    var ugprob = LogMath.LogToLinear(logugprob);
                    var bgprob = LogMath.LogToLinear(logbgprob);

                    var backoffbgprob = ugbackoff * ugprob;
                    double logbackoffbgprob = LogMath.LinearToLog(backoffbgprob);

                    ugNumerator[i] +=
                        (bgprob * logbgprob
                                - backoffbgprob * logbackoffbgprob) * logugprob;

                    ugDenominator[i] += (bgprob - backoffbgprob) * logugprob;
                    // dumpProbs(ugNumerator, ugDenominator, i, j, logugprob,
                    // logbgprob, ugprob, bgprob, backoffbgprob,
                    // logbackoffbgprob);
                }

                ugNumerator[i] += ugbackoff * (logugbackoff * s0 + r0);
                ugAvgLogProb[i] = ugDenominator[i] + ugbackoff * s0;
                ugDenominator[i] += ugbackoff * r0;

                // System.out.println("n/d " + ugNumerator[i] + " " +
                // ugDenominator[i]);

                _unigramSmearTerm[i] = (float) (ugNumerator[i] / ugDenominator[i]);
                // / unigramSmearTerm[i] =
                // logMath.linearToLog(ugNumerator[i] / ugDenominator[i]);
                // System.out.println("ugs " + unigramSmearTerm[i]);
            }

            for (var i = 0; i < _loadedBigramBuffers.Length; i++) 
            {
                this.LogInfo("Processed " + i
                                   + " of " + _loadedBigramBuffers.Length);
                var bigram = GetBigramBuffer(i);

                if (bigram == null)
                    continue;

                for (var j = 0; j < bigram.NumberNGrams; j++) {
                    float smearTerm;
                    var bgProb = bigram.GetNGramProbability(j);
                    var logbgbackoff =
                        _ngramBackoffTable[2][bgProb.BackoffID];
                    var bgbackoff = LogMath.LogToLinear(logbgbackoff);
                    var k = bigram.GetWordID(j);
                    var trigram = LoadTrigramBuffer(i, k);

                    if (trigram == null)
                        smearTerm = _unigramSmearTerm[k];
                    else {
                        double bgNumerator = 0;
                        double bgDenominator = 0;
                        for (var l = 0; l < trigram.NumberNGrams; l++) {
                            var m = trigram.GetWordID(l);
                            var logtgprob =
                                _ngramProbTable[2][trigram.GetProbabilityID(l)];
                            var tgprob = LogMath.LogToLinear(logtgprob);
                            var logbgprob = GetBigramProb(k, m);
                            var bgprob = LogMath.LogToLinear(logbgprob);
                            var logugprob = _unigrams[m].LogProbability;
                            var backofftgprob = bgbackoff * bgprob;
                            double logbackofftgprob =
                                LogMath.LinearToLog(backofftgprob);

                            bgNumerator += (tgprob * logtgprob - backofftgprob 
                                * logbackofftgprob) * logugprob;

                            bgDenominator += (tgprob - backofftgprob) * logugprob 
                                * logugprob;
                        }

                        bgNumerator +=
                            bgbackoff * (logbgbackoff * ugAvgLogProb[k] - ugNumerator[k]);
                        bgDenominator += bgbackoff * ugDenominator[k];
                        // bigram.ugsmear = bg_numerator / bg_denominator;
                        smearTerm = (float) (bgNumerator / bgDenominator);
                        _smearTermCount++;
                    }

                    PutSmearTerm(i, k, smearTerm);
                }
            }

            this.LogInfo("Smear count is " + _smearTermCount);
        }

        private void DumpProbs(double[] ugNumerator, double[] ugDenominator,int i,
                               int j, float logugprob, float logbgprob, double ugprob,
                               double bgprob, double backoffbgprob, double logbackoffbgprob) {

            this.LogInfo("ubo " + ugprob + ' ' + bgprob + ' ' +
                               backoffbgprob);
            this.LogInfo("logubo " + logugprob
                               + ' ' + logbgprob + ' ' + logbackoffbgprob);
            this.LogInfo("n/d " + j + ' '
                               + ugNumerator[i] + ' ' + ugDenominator[i]);

            this.LogInfo(ugprob + " " + bgprob + ' '
                             + backoffbgprob);
            this.LogInfo(" " + logugprob + ' '
                             + logbgprob + ' ' + logbackoffbgprob);
            this.LogInfo("  " + ugNumerator[i]
                               + ' ' + ugDenominator[i]);
        }

        /**
         * Writes the smear info to the given file
         *
         * @param filename the file to write the smear info to
         * @throws IOException if an error occurs on write
         */
        private void WriteSmearInfo(String filename)
        {
            var _out = new StreamWriter(filename);
            _out.Write(SmearMagic);
            this.LogInfo("writing " + _unigrams.Length);
            _out.Write(_unigrams.Length);

            for (var i = 0; i < _unigrams.Length; i++)
                _out.Write(_unigramSmearTerm[i]);

            for (var i = 0; i < _unigrams.Length; i++) 
            {
                this.LogInfo("Writing " + i + " of " + _unigrams.Length);
                var bigram = GetBigramBuffer(i);

                if (bigram == null) 
                {
                    _out.Write(0);
                    continue;
                }

                _out.Write(bigram.NumberNGrams);

                for (var j = 0; j < bigram.NumberNGrams; j++) 
                {
                    var k = bigram.GetWordID(j);
                    var smearTerm = GetSmearTerm(i, k);
                    _out.Write(k);
                    _out.Write(smearTerm.FloatValue());
                }
            }

            _out.Close();
        }

        /**
         * Reads the smear info from the given file
         *
         * @param filename where to read the smear info from
         * @throws IOException if an inconsistent file is found or on any general
         *         I/O error
         */
        private void ReadSmearInfo(String filename)
        {
            var @in = new FileStream(filename,FileMode.Open);

            if (@in.ReadInt() != SmearMagic) {
                @in.Close();
                throw new IOException("Bad smear format for " + filename);
            }

            if (@in.ReadInt() != _unigrams.Length) 
            {
                @in.Close();
                throw new IOException("Bad unigram length in " + filename);
            }

            _bigramSmearMap = new Dictionary<long, Float>();
            _unigramSmearTerm = new float[_unigrams.Length];
            this.LogInfo("Reading " + _unigrams.Length);

            for (var i = 0; i < _unigrams.Length; i++)
                _unigramSmearTerm[i] = @in.ReadFloat();

            for (var i = 0; i < _unigrams.Length; i++) 
            {
                this.LogInfo("Processed " + i + " of " 
                    + _loadedBigramBuffers.Length);
                var numBigrams = @in.ReadInt();
                var bigram = GetBigramBuffer(i);

                if (bigram.NumberNGrams != numBigrams) 
                {
                    @in.Close();
                    throw new IOException("Bad ngrams for unigram " + i +
                                          " Found " + numBigrams + " expected " +
                                          bigram.NumberNGrams);
                }

                for (var j = 0; j < numBigrams; j++) {
                    var k = bigram.GetWordID(j);
                    PutSmearTerm(i, k, @in.ReadFloat());
                }
            }

            @in.Close();
        }

        /**
         * Puts the smear term for the two words
         *
         * @param word1 the first word
         * @param word2 the second word
         * @param smearTerm the smear term
         */
        private void PutSmearTerm(int word1, int word2, float smearTerm) 
        {
            var bigramID = (((long) word1) << 32) | word2;
            _bigramSmearMap[bigramID]= smearTerm;
        }

        /**
         * Retrieves the smear term for the two words
         *
         * @param word1 the first word
         * @param word2 the second word
         * @return the smear term
         */
        private Float GetSmearTerm(int word1, int word2) 
        {
            var bigramID = (((long) word1) << 32) | word2;
            return _bigramSmearMap[bigramID];
        }

        /**
         * Retrieves the bigram probability for the two given words
         *
         * @param word1 the first word of the bigram
         * @param word2 the second word of the bigram
         * @return the log probability
         */
        private float GetBigramProb(int word1, int word2) {
            var bigram = GetBigramBuffer(word1);
            var bigramProbability = bigram.FindNGram(word2);
            return _ngramProbTable[1][bigramProbability.ProbabilityID];
        }
    }
}
