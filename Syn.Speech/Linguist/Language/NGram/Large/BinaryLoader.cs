using System;
using System.Diagnostics;
using System.Globalization;
using System.IO;
using System.Text;
using Syn.Logging;
using Syn.Speech.Helper;
using Syn.Speech.Linguist.Dictionary;
using Syn.Speech.Util;

//REFACTORED
namespace Syn.Speech.Linguist.Language.NGram.Large
{
    /// <summary>
    /// Reads a binary NGram language model file ("DMP file") generated by the SphinxBase sphinx_lm_convert.
    ///
    /// Note that all probabilities in the grammar are stored in LogMath log base format. Language 
    /// Probabilities in the language model file are stored in log 10 base. They are converted to 
    /// the LogMath base.
    /// </summary>
    public class BinaryLoader
    {
        private const string DarpaTgHeader = "Darpa Trigram LM";
        private const string DarpaQgHeader = "Darpa Quadrigram LM";

        // For convenience, NG Header is regular expression, so there is 2 extra characters in it.
        // Therefore, header.length() must be adjusted by -1 (and not +1), 
        // and we use Pattern.matches() for equality in header names.
        private const string DarpaNgHeader = "Darpa \\d-gram LM";

        private const int Log2NgramSegmentSize = 9;

        private const float MinProbability = -99.0f;
        private const int MaxProbTableSize = Integer.MAX_VALUE;

        private readonly LogMath _logMath;

        private readonly float _unigramWeight;
        private readonly float _languageWeight;
    
        private readonly double _wip;
    
        private Boolean _bigEndian = true;
        private readonly Boolean _applyLanguageWeightAndWip;

        private long _bytesRead;

        private long[] _nGramOffset;
        private int[] _numberNGrams;

        private int _startWordID;
        private int _endWordID;
    
        private int[][] _nGramSegmentTable;
        private float[][] _nGramProbTable;
        private float[][] _nGramBackoffTable;

        private readonly FileStream _file;

        // Bytes multiplier for LM (2 = 16 bits, 4 = 32 bits)

        /**
         * Initializes the binary loader
         *
         * @param location                  location of the model
         * @param format                    file format
         * @param applyLanguageWeightAndWip if true apply language weight and word insertion penalty
         * @param languageWeight            language weight
         * @param wip                       word insertion probability
         * @param unigramWeight             unigram weight
         * @throws IOException if an I/O error occurs
         */
        public BinaryLoader(FileInfo location, string format,
                            Boolean applyLanguageWeightAndWip,
                            float languageWeight, double wip, float unigramWeight)
            :this(format, applyLanguageWeightAndWip, languageWeight, wip, unigramWeight)
        {
            LoadModelLayout(new FileStream(location.FullName, FileMode.Open));
            _file = new FileStream(location.FullName, FileMode.Open);
        }


        /**
         * Initializes the binary loader
         *
         * @param format                    file format
         * @param applyLanguageWeightAndWip if true apply language weight and word insertion penalty
         * @param languageWeight            language weight
         * @param wip                       word insertion probability
         * @param unigramWeight             unigram weight
         */
        public BinaryLoader(String format, Boolean applyLanguageWeightAndWip, float
                languageWeight, double wip,
                float unigramWeight) 
        {
            _startWordID = -1;
            _endWordID = -1;
            _applyLanguageWeightAndWip = applyLanguageWeightAndWip;
            _logMath = LogMath.GetLogMath();
            _languageWeight = languageWeight;
            _wip = wip;
            _unigramWeight = unigramWeight;
        }

        public void Deallocate()
        {
            if (null != _file)
                _file.Close();
        }

        /**
         * Returns the number of unigrams
         *
         * @return the number of unigrams
         */
        public int GetNumberUnigrams() 
        {
            return GetNumberNGrams(1);
        }


        /**
         * Returns the number of bigrams
         *
         * @return the number of bigrams
         */
        public int GetNumberBigrams() 
        {
    	    return GetNumberNGrams(2);
        }


        /**
         * Returns the number of trigrams
         *
         * @return the number of trigrams
         */
        public int GetNumberTrigrams() 
        {
    	    return GetNumberNGrams(3);
        }
    
    
        /**
         * Returns the number of NGrams at
         * a specified N order.
         *
         * @param n			the desired order
         * @return the number of NGrams
         */
        public int GetNumberNGrams(int n) 
        {
    	    // Be sure that we don't overcome the model
    	    Debug.Assert((n <= MaxDepth) & (n > 0));
            return _numberNGrams[n - 1];
        }

    
        /**
         * Returns all the unigrams
         *
         * @return all the unigrams
         */

        public UnigramProbability[] Unigrams { get; private set; }


        /**
         * Returns all the bigram probabilities.
         *
         * @return all the bigram probabilities
         */
        public float[] GetBigramProbabilities() {
            return GetNGramProbabilities(2);
        }


        /**
         * Returns all the trigram probabilities.
         *
         * @return all the trigram probabilities
         */
        public float[] GetTrigramProbabilities() {
            return GetNGramProbabilities(3);
        }


        /**
         * Returns all the trigram backoff weights
         *
         * @return all the trigram backoff weights
         */
        public float[] GetTrigramBackoffWeights() {
            return GetNGramBackoffWeights(3);
        }


        /**
         * Returns the trigram segment table.
         *
         * @return the trigram segment table
         */
        public int[] GetTrigramSegments() {
            return GetNGramSegments(3);
        }


        /**
         * Returns the log of the bigram segment size
         *
         * @return the log of the bigram segment size
         */

        public int LogBigramSegmentSize { get; private set; }


        /**
         * Returns all the NGram probabilities at
         * a specified N order.
         *
         * @param n			the desired order
         * @return all the NGram probabilities
         */
        public float[] GetNGramProbabilities(int n) {
    	    // Be sure that we don't overcome the model
    	    Debug.Assert( (n <= MaxDepth) && (n > 1));
            return _nGramProbTable[n - 1];
        }

    
        /**
         * Returns all the NGram backoff weights at
         * a specified N order.
         *
         * @param n			the desired order
         * @return all the NGram backoff weights
         */
        public float[] GetNGramBackoffWeights(int n) {
    	    // Be sure that we don't overcome the model
    	    Debug.Assert( (n <= MaxDepth) & (n > 2));
            return _nGramBackoffTable[n - 1];
        }


        /**
         * Returns the NGram segment table at
         * a specified order.
         *
         * @param n			the desired order
         * @return the NGram segment table
         */
        public int[] GetNGramSegments(int n) 
        {
    	    // Be sure that we don't overcome the model
    	    Debug.Assert( (n <= MaxDepth) & (n > 2));
            return _nGramSegmentTable[n - 1];
        }


        /**
         * Returns the log of the NGram segment size
         *
         * @return the log of the NGram segment size
         */
        public int GetLogNGramSegmentSize() {
            return LogBigramSegmentSize;
        }


        /**
         * Returns all the words.
         *
         * @return all the words
         */

        public string[] Words { get; private set; }


        /**
         * Returns the location (or offset) into the file where bigrams start.
         *
         * @return the location of the bigrams
         */
        public long GetBigramOffset() {
            return GetNGramOffset(2);
        }


        /**
         * Returns the location (or offset) into the file where trigrams start.
         *
         * @return the location of the trigrams
         */
        public long GetTrigramOffset() {
            return GetNGramOffset(3);
        }
    
    
        /**
         * Returns the location (or offset) into the file where NGrams start
         * at a specified N order.
         *
         * @param n			the desired order
         * @return the location of the bigrams
         */
        public long GetNGramOffset(int n) {
    	    // Be sure that we don't overcome the model
    	    Debug.Assert((n <= MaxDepth) & (n > 1));
            return _nGramOffset[n - 1];
        }


        /**
         * Returns the maximum depth of the language model
         *
         * @return the maximum depth of the language model
         */

        public int MaxDepth { get; private set; }


        /**
         * Returns true if the loaded file is in big-endian.
         *
         * @return true if the loaded file is big-endian
         */
        public Boolean GetBigEndian() 
        {
            return _bigEndian;
        }


        /**
         * Returns the multiplier for the size of a NGram
         * (1 for 16 bits, 2 for 32 bits).
         *
         * @return the multiplier for the size of a NGram
         */

        public int BytesPerField { get; private set; }


        /**
         * Loads the contents of the memory-mapped file starting at the given position and for the given size, into a byte
         * buffer. This method is implemented because MappedByteBuffer.load() does not work properly.
         *
         * @param position the starting position in the file
         * @param size     the number of bytes to load
         * @return the loaded ByteBuffer
         * @throws java.io.IOException
         */
        public virtual sbyte[] LoadBuffer(long position, int size)
        {
            _file.Seek(position, SeekOrigin.Begin);
            var bytes = new byte[size];
            if (_file.Read(bytes,0,size) != size) 
            {
                throw new IOException("Incorrect number of bytes read. Size = " + size + ". Position =" + position + ".");
            }
            var toReturn = bytes.ToSignedBytes();
            return toReturn;
        }


        /**
         * Loads the language model from the given file.
         *
         * @param inputStream stream to read the language model data
         * @throws java.io.IOException
         */
        protected void LoadModelLayout(Stream fileStream)
        {

            //8K Buffer applied
            var stream = new BufferedStream(fileStream , 8192);

            // read standard header string-size; set bigEndian flag
            ReadHeader(stream);

            // +1 is the sentinel unigram at the end
            Unigrams = ReadUnigrams(stream, _numberNGrams[0] + 1, _bigEndian);
        
            SkipNGrams(stream);

            // Read the NGram prob & bow tables
            for (var i = 1; i < MaxDepth; i++) {      	
        	    if (_numberNGrams[i] > 0) {
        		    if (i == 1) {
        			    _nGramProbTable[i] = ReadFloatTable(stream, _bigEndian);
        		    }
        		    else {
        			    _nGramBackoffTable[i] = ReadFloatTable(stream, _bigEndian);
        			    _nGramProbTable[i] = ReadFloatTable(stream, _bigEndian);
        			
        			    var nMinus1GramSegmentSize = 1 << LogBigramSegmentSize;
        			    var nGramSegTableSize = ((_numberNGrams[i - 1] + 1) / nMinus1GramSegmentSize) + 1;
        			
        			    _nGramSegmentTable[i] = ReadIntTable(stream, _bigEndian, nGramSegTableSize);
        		    }
        	    }
            }
        
            // read word string names
            var wordsStringLength = ReadInt(stream, _bigEndian);
            if (wordsStringLength <= 0) 
            {
                throw new Exception("Bad word string size: " + wordsStringLength);
            }

            // read the string of all words
            Words = ReadWords(stream, wordsStringLength, _numberNGrams[0]);

            // A voir
            if (_startWordID > -1) {
                var unigram = Unigrams[_startWordID];
                unigram.SetLogProbability(MinProbability);
            }
            if (_endWordID > -1) {
                var unigram = Unigrams[_endWordID];
                unigram.SetLogBackoff(MinProbability);
            }

            ApplyUnigramWeight();
        
            if (_applyLanguageWeightAndWip) {
        	    for (var i = 0; i <= MaxDepth; i++) {
        		    ApplyLanguageWeight(ref _nGramProbTable[i], _languageWeight);
        		    ApplyWip(ref _nGramProbTable[i], _wip);
        		
        		    if (i > 1) {
        			    ApplyLanguageWeight(ref _nGramBackoffTable[i], _languageWeight);
        		    }
        	    }
            }

            stream.Close();
        }


        /**
         * Reads the LM file header
         *
         * @param stream the data stream of the LM file
         * @throws java.io.IOException
         */
        private void ReadHeader(Stream stream)
        {
            var headerLength = ReadInt(stream, _bigEndian);

            if ((headerLength != DarpaTgHeader.Length + 1) && (headerLength != DarpaQgHeader.Length + 1) && (headerLength != DarpaNgHeader.Length- 1)) 
            { // not big-endian
                headerLength = Utilities.SwapInteger(headerLength);
                if (headerLength == (DarpaTgHeader.Length + 1) || headerLength == (DarpaQgHeader.Length + 1) || headerLength == (DarpaNgHeader.Length - 1)) 
                {
                    _bigEndian = false;
                    // System.out.println("Little-endian");
                } 
                else {
                    throw new Exception("Bad binary LM file magic number: "
                            + headerLength + ", not an LM dumpfile?");
                }
            } 
            else {
                // System.out.println("Big-endian");
            }

            // read and verify standard header string
            var header = ReadString(stream, headerLength - 1);
            stream.ReadByte(); // read the '\0'
            _bytesRead++;

            if (!header.Equals(DarpaTgHeader) & !header.Equals(DarpaQgHeader) /*& !Pattern.matches(DARPA_NG_HEADER, header)*/) 
            {
                throw new Exception("Bad binary LM file header: " + header);
            }
            else 
            {
        	    if (header.Equals(DarpaTgHeader))
        		    MaxDepth = 3;
        	    else if (header.Equals(DarpaQgHeader))
        		    MaxDepth = 4;
        	    else
        	    {
        	        var p = Pattern.Compile("\\d");
        	        var m = p.Matcher(header);
                    //Match m = Regex.Match(header, "\\d");
                    MaxDepth = Convert.ToInt32(m.Group(0), CultureInfo.InvariantCulture.NumberFormat);
        	    }
            }
   
            // read LM filename string size and string
            var fileNameLength = ReadInt(stream, _bigEndian);
            SkipStreamBytes(stream, fileNameLength);

            _numberNGrams = new int[MaxDepth];
            _nGramOffset = new long[MaxDepth];
            _nGramProbTable = new float[MaxDepth][];
            _nGramBackoffTable = new float[MaxDepth][];
            _nGramSegmentTable = new int[MaxDepth][];
        
            _numberNGrams[0] = 0;
            LogBigramSegmentSize = Log2NgramSegmentSize;

            // read version number, if present. it must be <= 0.

            var version = ReadInt(stream, _bigEndian);
            // System.out.println("Version: " + version);

            BytesPerField = 2;
        
            if (version <= 0) { // yes, its the version number
                ReadInt(stream, _bigEndian); // read and skip timestamp

                // Means we are going 32 bits.
                if (version <= -3)
            	    BytesPerField = 4;
            
                // read and skip format description
                int formatLength;
                for (; ;) 
                {
                    if ((formatLength = ReadInt(stream, _bigEndian)) == 0) {
                        break;
                    }
                    _bytesRead += stream.Skip(formatLength);
                }

                // read log NGram segment size if present
                // only for 16 bits version 2 LM
                if (version == -2) {
                    LogBigramSegmentSize = ReadInt(stream, _bigEndian);
                    if (LogBigramSegmentSize < 1 || LogBigramSegmentSize > 15) {
                        throw new Exception("log2(bg_seg_sz) outside range 1..15");
                    }
                }

                _numberNGrams[0] = ReadInt(stream, _bigEndian);
            } else {
        	    _numberNGrams[0] = version;
            }

            if (_numberNGrams[0] <= 0) 
            {
                throw new Exception("Bad number of unigrams: " + _numberNGrams[0]
                        + ", must be > 0.");
            }

            for (var i = 1; i < MaxDepth; i++) 
            {
                if ((_numberNGrams[i] = ReadInt(stream, _bigEndian)) < 0) 
                {
                    throw new Exception("Bad number of " + i + "-grams: " + _numberNGrams[i]);
                }
            }
        }


        /**
         * Skips the NGrams of the LM.
         * 
         * @param stream
         *            the source of data
         * @throws java.io.IOException
         */
        private void SkipNGrams(Stream stream)
        {
            long bytesToSkip;

            _nGramOffset[1] = _bytesRead;
            bytesToSkip = (_numberNGrams[1] + 1) * LargeNGramModel.BytesPerNgram * BytesPerField;
            SkipStreamBytes(stream, bytesToSkip);

            for (var i = 2; i < MaxDepth; i++)
            {
                if (_numberNGrams[i] > 0 && i < MaxDepth - 1)
                {
                    _nGramOffset[i] = _bytesRead;
                    bytesToSkip = (_numberNGrams[i] + 1) * (long)LargeNGramModel.BytesPerNgram * BytesPerField;
                    SkipStreamBytes(stream, bytesToSkip);
                }
                else if (_numberNGrams[i] > 0 && i == MaxDepth - 1)
                {
                    _nGramOffset[i] = _bytesRead;
                    bytesToSkip = _numberNGrams[i] * (long)LargeNGramModel.BytesPerNmaxgram * BytesPerField;
                    SkipStreamBytes(stream, bytesToSkip);
                }
            }
        }
    
        /**
         * Reliable skip
         * 
         * @param stream stream
         * @param bytes number of bytes
         */
        private void SkipStreamBytes(Stream stream, long bytes)
        {
            while (bytes > 0)
            {
                var skipped = stream.Skip(bytes);
                _bytesRead += skipped;
                bytes -= skipped;
            }
        }
    

        
        /// <summary>
        /// Apply the unigram weight to the set of unigrams
        /// </summary>
        private void ApplyUnigramWeight() 
        {
            var logUnigramWeight = _logMath.LinearToLog(_unigramWeight);
            var logNotUnigramWeight = _logMath.LinearToLog(1.0f - _unigramWeight);
            var logUniform = _logMath.LinearToLog(1.0f / (_numberNGrams[0]));

            var logWip = _logMath.LinearToLog(_wip);

            var p2 = logUniform + logNotUnigramWeight;

            for (var i = 0; i < _numberNGrams[0]; i++) 
            {
                var unigram = Unigrams[i];

                var p1 = unigram.LogProbability;

                if (i != _startWordID) {
                    p1 += logUnigramWeight;
                    p1 = _logMath.AddAsLinear(p1, p2);
                }

                if (_applyLanguageWeightAndWip) {
                    p1 = p1 * _languageWeight + logWip;
                    unigram.SetLogBackoff(unigram.LogBackoff * _languageWeight);
                }

                if (unigram.WordID == 2520)
                {
                    this.LogInfo("TEST");
                }

                unigram.SetLogProbability(p1);
            }
        }


        /** Apply the language weight to the given array of probabilities.
         */
        private void ApplyLanguageWeight(ref float[] logProbabilities,
                                         float languageWeightValue) 
        {
            for (var i = 0; i < logProbabilities.Length; i++) {
                logProbabilities[i] = logProbabilities[i] * languageWeightValue;
            }
        }


        /** Apply the WIP to the given array of probabilities.
        */
        private void ApplyWip(ref float[] logProbabilities, double wip) 
        {
            var logWip = _logMath.LinearToLog(wip);
            for (var i = 0; i < logProbabilities.Length; i++) 
            {
                logProbabilities[i] = logProbabilities[i] + logWip;
            }
        }


        /**
         * Reads the probability table from the given DataInputStream.
         *
         * @param stream    the DataInputStream from which to read the table
         * @param bigEndian true if the given stream is bigEndian, false otherwise
         * @throws java.io.IOException
         */
        private float[] ReadFloatTable(Stream stream, Boolean bigEndian)
        {

            var numProbs = ReadInt(stream, bigEndian);
            if (numProbs <= 0 || numProbs > MaxProbTableSize) 
            {
                throw new Exception("Bad probabilities table size: " + numProbs);
            }

            var probTable = new float[numProbs];

            for (var i = 0; i < numProbs; i++) {
        	    //probTable[i] = readFloat(stream, bigEndian);
                probTable[i] = _logMath.Log10ToLog(ReadFloat(stream, bigEndian));
            }

            return probTable;
        }


        /**
         * Reads a table of integers from the given DataInputStream.
         *
         * @param stream    the DataInputStream from which to read the table
         * @param bigEndian true if the given stream is bigEndian, false otherwise
         * @param tableSize the size of the NGram segment table
         * @return the NGram segment table, which is an array of integers
         * @throws java.io.IOException
         */
        private int[] ReadIntTable(Stream stream, Boolean bigEndian, int tableSize)
        {
            var numSegments = ReadInt(stream, bigEndian);
            if (numSegments != tableSize) 
            {
                throw new Exception("Bad NGram seg table size: " + numSegments);
            }
            var segmentTable = new int[numSegments];
            for (var i = 0; i < numSegments; i++) {
                segmentTable[i] = ReadInt(stream, bigEndian);
            }
            return segmentTable;
        }


        /**
         * Read in the unigrams in the given DataInputStream.
         *
         * @param stream         the DataInputStream to read from
         * @param numberUnigrams the number of unigrams to read
         * @param bigEndian      true if the DataInputStream is big-endian, false otherwise
         * @return an array of UnigramProbability index by the unigram ID
         * @throws java.io.IOException
         */
        private UnigramProbability[] ReadUnigrams(Stream stream,int numberUnigrams, Boolean bigEndian)
        {

            var unigrams = new UnigramProbability[numberUnigrams];

            for (var i = 0; i < numberUnigrams; i++) {

                // read unigram ID, unigram probability, unigram backoff weight
                var unigramID = ReadInt(stream, bigEndian);
            
                /* Some tools to convert to DMP doesn't store ID's in unigrams */
                if (unigramID < 1) 
            	    unigramID = i;

                // if we're not reading the sentinel unigram at the end,
                // make sure that the unigram IDs are consecutive
                if (i != (numberUnigrams - 1)) 
                {
                    Debug.Assert (unigramID == i);
                }

                var unigramProbability = ReadFloat(stream, bigEndian);
                var unigramBackoff = ReadFloat(stream, bigEndian);
                var firstBigramEntry = ReadInt(stream, bigEndian);

                var logProbability = _logMath.Log10ToLog(unigramProbability);
                var logBackoff = _logMath.Log10ToLog(unigramBackoff);

                unigrams[i] = new UnigramProbability(unigramID, logProbability,
                        logBackoff, firstBigramEntry);
            }

            return unigrams;
        }


        /**
         * Reads an integer from the given DataInputStream.
         *
         * @param stream    the DataInputStream to read from
         * @param bigEndian true if the DataInputStream is in bigEndian, false otherwise
         * @return the integer read
         * @throws java.io.IOException
         */
        private int ReadInt(Stream stream, Boolean bigEndian)
        {
            _bytesRead += 4;
            if (bigEndian) 
            {
                return stream.ReadByte() << 24 | stream.ReadByte() << 16 | stream.ReadByte() << 8 | stream.ReadByte();
            } 
            else 
            {
                return Utilities.ReadLittleEndianInt(stream);
            }
        }


        /**
         * Reads a float from the given DataInputStream.
         *
         * @param stream    the DataInputStream to read from
         * @param bigEndian true if the DataInputStream is in bigEndian, false otherwise
         * @return the float read
         * @throws java.io.IOException
         */
        private float ReadFloat(Stream stream, Boolean bigEndian)
        {
            _bytesRead += 4;
            if (bigEndian) 
            {
                var val=stream.ReadByte() << 24 | stream.ReadByte() << 16 | stream.ReadByte() << 8 | stream.ReadByte();
                return Convert.ToSingle(val, CultureInfo.InvariantCulture.NumberFormat);
            } 
            else 
            {
                return Utilities.ReadLittleEndianFloat(stream);
            }
        }



         /**
          * Reads a string of the given length from the given DataInputStream. It is assumed that the DataInputStream
          * contains 8-bit chars.
          *
          * @param stream the DataInputStream to read from
          * @param length the number of characters in the returned string
          * @return a string of the given length from the given DataInputStream
          * @throws java.io.IOException
          */
         private string ReadString(Stream stream, int length)
         {
             var builder = new StringBuilder();
             var bytes = new byte[length];
             _bytesRead += stream.Read(bytes,0,length);
 
             for (var i = 0; i < length; i++) 
             {
                 builder.Append((char) bytes[i]);
             }
             return builder.ToString();
         }
 
 
         /**
          * Reads a series of consecutive Strings from the given stream.
          *
          * @param stream         the DataInputStream to read from
          * @param length         the total length in bytes of all the Strings
          * @param numberUnigrams the number of string to read
          * @return an array of the Strings read
          * @throws java.io.IOException
          */
         private String[] ReadWords(Stream stream, int length,int numberUnigrams)
         {
             var words = new String[numberUnigrams];
             var bytes = new byte[length];
             _bytesRead += stream.Read(bytes,0,length);
 
             var s = 0;
             var wordStart = 0;
             for (var i = 0; i < length; i++) 
             {
                 var c = (char) (bytes[i] & 0xFF);
                 _bytesRead++;
                 if (c == '\0') 
                 {
                     // if its the end of a string, add it to the 'words' array
                     words[s] = Encoding.ASCII.GetString(bytes, wordStart, i - wordStart);
                     wordStart = i + 1;
                     if (words[s].Equals(IDictionary.SentenceStartSpelling)) 
                     {
                         _startWordID = s;
                     } 
                     else if (words[s].Equals(IDictionary.SentenceEndSpelling)) 
                     {
                         _endWordID = s;
                     }
                     s++;
                 }
             }
             Debug.Assert (s == numberUnigrams);
             return words;
         }

    }
}
